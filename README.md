
# Multi-Agent Reinforcement Learning for High-Frequency Trading

This repository contains the implementation of a multi-agent RL system inspired by the EarnHFT framework.  
It includes hierarchical decision-making with a router agent that selects the best-performing policy based on market conditions.

---

##  Project Structure

```
â”œâ”€â”€ agents/                     # Reinforcement learning agents (e.g., DDQN)
â”‚   â””â”€â”€ ddqn_agent.py

â”œâ”€â”€ envs/                       # Market simulation environment
â”‚   â””â”€â”€ market_env.py

â”œâ”€â”€ q_teacher/                 # Optimal Q-value computation for supervised guidance
â”‚   â”œâ”€â”€ optimal_value.py
â”‚   â””â”€â”€ q_trainer.py

â”œâ”€â”€ stage2_diverse_pool/       # Stage 2: Diverse agent pool creation
â”‚   â”œâ”€â”€ config.py              # Î², Î¸, window settings
â”‚   â”œâ”€â”€ sampler.py             # Biased sampling via KDE
â”‚   â”œâ”€â”€ selector.py            # Agent selection based on trend label
â”‚   â””â”€â”€ trend_segmentation.py  # Trend segmentation using slope + DTW

â”œâ”€â”€ stage3_router/             # Stage 3: High-level policy router
â”‚   â”œâ”€â”€ evaluate_router.py     # Evaluate router performance
â”‚   â”œâ”€â”€ high_level_env.py      # Router's custom environment
â”‚   â”œâ”€â”€ router_agent.py        # Router agent logic
â”‚   â””â”€â”€ router_trainer.py      # Training script for router agent

â”œâ”€â”€ utils/                     # Utility functions and data loaders
â”‚   â””â”€â”€ loader.py

â”œâ”€â”€ results/                   # Evaluation results and visuals
â”‚   â”œâ”€â”€ router_report.md
â”‚   â”œâ”€â”€ selected_betas.pkl
â”‚   â”œâ”€â”€ trained_agents_pool.pkl
â”‚   â””â”€â”€ router_metrics.pkl

â”œâ”€â”€ train_multiagent.py        # Main script for training agent pool
â”œâ”€â”€ trainer_multiagent.py      # Alternate training script for stage 2
â”œâ”€â”€ train_qteacher.py          # Supervised Q* training
â”œâ”€â”€ run_router.py              # Run router with selected agents
â”œâ”€â”€ eval.py                    # Evaluation and reporting
â”œâ”€â”€ selecting.py               # Selection logic (stage 1â€“2 transition)

â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---

## ğŸ“ˆ Sample Evaluation Result

ğŸ“„ [View Full Report](./results/router_report.md)

| Metric              | Value       |
|---------------------|-------------|
| âœ… Average Reward    | 1.50        |
| ğŸ’° Average Profit    | 97.05       |
| ğŸ“ˆ Sharpe Ratio      | 9.77        |
| ğŸ¥‡ Average Win Rate  | 72.54%      |
| ğŸ’¹ Total Profit      | 19,410.00   |
| ğŸ¦ Final Balance     | 119,410.00  |
| ğŸ“Š Total Return      | 19.41%      |
| ğŸ“‰ Max Drawdown      | 9.26%       |

---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Running

```bash
python train_multiagent.py
python run_router.py
python eval.py
```

---

## ğŸ“š Credits

Inspired by [EarnHFT: AAAI 2024 Paper](https://arxiv.org/abs/2401.04283)
